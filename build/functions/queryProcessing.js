// Service for processing user text and generating optimized search queries using AI
export class QueryProcessingService {
    static REQUEST_TIMEOUT = 10000; // 10 seconds timeout for AI requests
    /**
     * Generates optimized search queries from user input using AI
     * @param userText - The original user statement (up to 1000 characters)
     * @param apiKey - OpenRouter API key for AI processing
     * @returns Array of 3 optimized search queries
     */
    static async generateSearchQueries(userText, apiKey) {
        if (!userText || userText.trim().length === 0) {
            throw new Error("User text cannot be empty");
        }
        if (userText.length > 1500) {
            throw new Error("User text exceeds maximum length of 1500 characters");
        }
        try {
            const systemPrompt = this.createQueryExtractionPrompt();
            const userPrompt = `ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÐµÐµ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¸ ÑÐ¾Ð·Ð´Ð°Ð¹ 3 Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ„Ð°ÐºÑ‚Ð¾Ð²:

"${userText}"

Ð’ÐµÑ€Ð½Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON Ð¼Ð°ÑÑÐ¸Ð²Ð° Ñ Ð¾Ð±ÑŠÐµÐºÑ‚Ð°Ð¼Ð¸, ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‰Ð¸Ð¼Ð¸ Ð¿Ð¾Ð»Ñ: query, priority, type.`;
            const aiResponse = await this.callAI(systemPrompt, userPrompt, apiKey);
            const queries = this.parseAIResponse(aiResponse);
            if (queries.length === 0) {
                // Fallback: create basic queries from user text if AI fails
                return this.createFallbackQueries(userText);
            }
            return queries;
        }
        catch (error) {
            console.error("Query generation failed:", error.message);
            // Fallback to basic keyword extraction
            return this.createFallbackQueries(userText);
        }
    }
    /**
     * Creates the system prompt for AI query extraction
     */
    static createQueryExtractionPrompt() {
        const currentDate = new Date().toLocaleDateString('ru-RU', {
            year: 'numeric',
            month: 'long',
            day: 'numeric'
        });
        return `Ð¢Ñ‹ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸ÑÑ‚ Ð¿Ð¾ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸ÑŽ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ñ… Ñ„Ð°ÐºÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿Ñ€Ð°Ð²Ð´Ð¸Ð²Ð¾ÑÑ‚Ð¸ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹. 

Ð¡ÐµÐ³Ð¾Ð´Ð½ÑÑˆÐ½ÑÑ Ð´Ð°Ñ‚Ð°: ${currentDate}

Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°: Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ€Ð¾Ð²Ð½Ð¾ 3 Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ñ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ð¾Ð¼Ð¾Ð³ÑƒÑ‚ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ„Ð°ÐºÑ‚Ð¾Ð².

Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ Ðº Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°Ð¼:
- ÐšÐ°Ð¶Ð´Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ 2-9 ÑÐ»Ð¾Ð²
- Ð¤Ð¾ÐºÑƒÑÐ¸Ñ€ÑƒÐ¹ÑÑ Ð½Ð° Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼Ñ‹Ñ… Ñ„Ð°ÐºÑ‚Ð°Ñ…, Ð° Ð½Ðµ Ð½Ð° Ð¼Ð½ÐµÐ½Ð¸ÑÑ…
- ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð½ÐµÐ´Ð°Ð²Ð½Ð¸Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ Ð¸ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ñ
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð¸ Ð¸Ð¼ÐµÐ½Ð° Ð¸Ð· Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°
- Ð•ÑÐ»Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ ÐµÑÑ‚ÑŒ Ð³Ð¾Ð´ Ð¸Ð»Ð¸ Ñ†Ð¸Ñ„Ñ€Ð° Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¸Ñ… Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ

Ð¢Ð¸Ð¿Ñ‹ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²:
- factual: Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ñ… Ñ„Ð°ÐºÑ‚Ð¾Ð², Ñ†Ð¸Ñ„Ñ€, Ð´Ð°Ñ‚
- event: Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹, Ð¿Ñ€Ð¾Ð¸ÑÑˆÐµÑÑ‚Ð²Ð¸Ð¹, Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹
- opinion: Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° ÑÐ¿Ð¾Ñ€Ð½Ñ‹Ñ… ÑƒÑ‚Ð²ÐµÑ€Ð¶Ð´ÐµÐ½Ð¸Ð¹, Ð¾Ñ†ÐµÐ½Ð¾Ðº

ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ñ‹:
- high: ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ„Ð°ÐºÑ‚Ñ‹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¼Ð¾Ð¶Ð½Ð¾ Ð»ÐµÐ³ÐºÐ¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ
- medium: Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸, Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‰Ð¸Ðµ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
- low: Ð²ÑÐ¿Ð¾Ð¼Ð¾Ð³Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ

Ð’ÐµÑ€Ð½Ð¸ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¢ÐžÐ›Ð¬ÐšÐž Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ JSON Ð¼Ð°ÑÑÐ¸Ð²Ð°:
[
  {"query": "Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ 1", "priority": "high", "type": "factual"},
  {"query": "Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ 2", "priority": "medium", "type": "event"},
  {"query": "Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ 3", "priority": "medium", "type": "factual"}
]`;
    }
    /**
     * Makes AI API call to generate queries
     */
    static async callAI(systemPrompt, userPrompt, apiKey) {
        // Use the same fallback models as in truthCheck.ts
        const models = [
            "tngtech/deepseek-r1t2-chimera:free",
            "microsoft/mai-ds-r1:free",
            "google/gemini-2.0-flash-exp:free",
            "mistralai/mistral-small-3.2-24b-instruct:free",
            "deepseek/deepseek-r1-0528:free",
            "deepseek/deepseek-chat-v3-0324:free",
            "deepseek/deepseek-r1:free"
        ];
        let lastError = null;
        let attemptCount = 0;
        console.log("=== QUERY GENERATION REQUEST ===");
        console.log(`Timestamp: ${new Date().toISOString()}`);
        console.log(`User text for query generation: "${userPrompt}"`);
        console.log(`User text length: ${userPrompt.length} characters`);
        console.log("===============================");
        // Try each model until one works
        for (const model of models) {
            attemptCount++;
            console.log(`\n--- Query Generation Attempt ${attemptCount}/${models.length} with model: ${model} ---`);
            try {
                const controller = new AbortController();
                const timeoutId = setTimeout(() => controller.abort(), this.REQUEST_TIMEOUT);
                const requestBody = {
                    model: model,
                    messages: [
                        { role: "system", content: systemPrompt },
                        { role: "user", content: userPrompt }
                    ],
                    temperature: 0.3, // Lower temperature for more consistent results
                    max_tokens: 500 // Limit response length
                };
                console.log(`Query generation request body:`, JSON.stringify(requestBody, null, 2));
                const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${apiKey}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify(requestBody),
                    signal: controller.signal
                });
                clearTimeout(timeoutId);
                console.log(`Query generation response status: ${response.status} ${response.statusText}`);
                if (!response.ok) {
                    let errorDetails = "";
                    try {
                        const errorJson = await response.json();
                        errorDetails = JSON.stringify(errorJson, null, 2);
                        console.log(`Query generation error response:`, errorDetails);
                    }
                    catch (parseError) {
                        console.log(`Could not parse query generation error response:`, parseError);
                    }
                    console.error(`âŒ Query generation model ${model} failed with status ${response.status}`);
                    // If rate limit (429), try next model
                    if (response.status === 429) {
                        lastError = `Rate limit (429) for model ${model}`;
                        console.log(`â³ Query generation rate limited, trying next model...`);
                        continue;
                    }
                    lastError = `Model: ${model} | Error: ${response.status} ${response.statusText}`;
                    console.log(`ðŸ”„ Query generation HTTP error, trying next model...`);
                    continue;
                }
                // Success - process response
                const data = await response.json();
                console.log(`âœ… Successful query generation response from ${model}`);
                console.log(`Full query generation response:`, JSON.stringify(data, null, 2));
                if (data.usage) {
                    console.log(`Query generation token usage:`, data.usage);
                }
                const content = data.choices?.[0]?.message?.content;
                console.log(`Query generation raw content: "${content}"`);
                console.log(`Query generation content length: ${content?.length || 0} characters`);
                if (!content) {
                    console.error(`âŒ Query generation model ${model} returned no content`);
                    lastError = `No content received from model ${model}`;
                    continue;
                }
                if (content.trim().length === 0) {
                    console.error(`âŒ Query generation model ${model} returned empty content`);
                    lastError = `Empty content received from model ${model}`;
                    continue;
                }
                console.log(`âœ… Query generation model ${model} provided valid content`);
                return content;
            }
            catch (error) {
                if (error.name === 'AbortError') {
                    console.error(`âŒ Query generation timeout for model ${model}`);
                    lastError = `Timeout for model ${model}`;
                }
                else {
                    console.error(`âŒ Query generation exception with model ${model}:`, error);
                    lastError = error;
                }
                continue;
            }
        }
        // If all models failed
        console.error(`ðŸ’¥ ALL QUERY GENERATION MODELS FAILED`);
        console.error(`Total query generation attempts: ${attemptCount}`);
        console.error(`Last query generation error:`, lastError);
        throw new Error(`All AI models failed. Last error: ${lastError}`);
    }
    /**
     * Parses AI response and extracts search queries
     */
    static parseAIResponse(response) {
        console.log(`=== PARSING AI RESPONSE FOR QUERIES ===`);
        console.log(`Raw AI response: "${response}"`);
        console.log(`Response length: ${response.length} characters`);
        try {
            // Try to extract JSON from response
            const jsonMatch = response.match(/\[[\s\S]*?\]/);
            if (!jsonMatch) {
                console.error(`âŒ No JSON array found in AI response`);
                console.error(`Response content: "${response}"`);
                throw new Error("No JSON array found in AI response");
            }
            console.log(`âœ… Found JSON in response: "${jsonMatch[0]}"`);
            const queries = JSON.parse(jsonMatch[0]);
            console.log(`âœ… Successfully parsed JSON, found ${queries.length} raw queries`);
            console.log(`Raw parsed queries:`, queries);
            // Validate and filter queries
            const validQueries = queries
                .filter(q => {
                const isValid = q.query && q.query.trim().length > 0;
                if (!isValid) {
                    console.warn(`âš ï¸ Filtering out invalid query:`, q);
                }
                return isValid;
            })
                .filter(q => {
                const isReasonableLength = q.query.length <= 100;
                if (!isReasonableLength) {
                    console.warn(`âš ï¸ Filtering out too long query (${q.query.length} chars):`, q.query);
                }
                return isReasonableLength;
            })
                .slice(0, 3); // Ensure exactly 3 queries
            console.log(`âœ… After filtering: ${validQueries.length} valid queries`);
            // Fill missing fields with defaults
            const finalQueries = validQueries.map(q => ({
                query: q.query.trim(),
                priority: q.priority || 'medium',
                type: q.type || 'factual'
            }));
            console.log(`âœ… Final processed queries:`, finalQueries);
            console.log(`========================================`);
            return finalQueries;
        }
        catch (error) {
            console.error(`âŒ Failed to parse AI response for queries:`, error.message);
            console.error(`Error stack:`, error.stack);
            console.error(`AI response was: "${response}"`);
            console.error(`Response type:`, typeof response);
            console.error(`========================================`);
            return [];
        }
    }
    /**
     * Creates fallback queries when AI processing fails
     */
    static createFallbackQueries(userText) {
        // Extract key words and phrases for basic search
        const cleanText = userText.toLowerCase()
            .replace(/[^\u0400-\u04FF\u0500-\u052F\u2DE0-\u2DFF\uA640-\uA69F\u1C80-\u1C8F\w\s]/g, ' ') // Keep Cyrillic and Latin
            .replace(/\s+/g, ' ')
            .trim();
        // Extract important words (longer than 3 characters)
        const words = cleanText.split(' ')
            .filter(word => word.length > 3)
            .slice(0, 10); // Limit to first 10 important words
        const queries = [];
        // Create 3 different query strategies
        if (words.length > 0) {
            // Query 1: First half of important words
            const firstHalf = words.slice(0, Math.ceil(words.length / 2)).join(' ');
            if (firstHalf.length > 0) {
                queries.push({
                    query: firstHalf,
                    priority: 'high',
                    type: 'factual'
                });
            }
            // Query 2: Second half of important words  
            const secondHalf = words.slice(Math.ceil(words.length / 2)).join(' ');
            if (secondHalf.length > 0) {
                queries.push({
                    query: secondHalf,
                    priority: 'medium',
                    type: 'event'
                });
            }
            // Query 3: Most important words (first few)
            const topWords = words.slice(0, 4).join(' ');
            if (topWords.length > 0 && topWords !== firstHalf) {
                queries.push({
                    query: topWords,
                    priority: 'medium',
                    type: 'factual'
                });
            }
        }
        // If we still don't have enough queries, use the original text (truncated)
        while (queries.length < 3) {
            const truncatedText = userText.substring(0, 50).trim();
            queries.push({
                query: truncatedText,
                priority: 'low',
                type: 'factual'
            });
        }
        return queries.slice(0, 3); // Ensure exactly 3 queries
    }
}
